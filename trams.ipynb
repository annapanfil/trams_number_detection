{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ad6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from matplotlib import pylab as plt  \n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from pylab import imread\n",
    "\n",
    "import skimage\n",
    "from skimage import morphology, measure, draw, feature, exposure\n",
    "from skimage.color import rgb2hsv, rgb2gray\n",
    "from skimage.morphology import square\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import sobel\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "import cv2\n",
    "\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4567de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array(arr, cols=3):\n",
    "    \"Show a mosaic of images list and save it to jpg\"\n",
    "    rows = ceil(len(arr)/cols)\n",
    "    plt.figure(figsize=(cols*30,rows*20))\n",
    "    \n",
    "    for i,img in enumerate(arr):\n",
    "        ax = plt.subplot(rows, cols, i+1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        imshow(img, cmap='gray')\n",
    "#     plt.savefig(\"tramwaje\")\n",
    "\n",
    "def show(*args):\n",
    "    \"\"\"Show multiple images in a row\"\"\"\n",
    "    plt.figure(figsize=(20,12))\n",
    "    for i,img in enumerate(args):\n",
    "        plt.subplot(1, len(args), i+1)\n",
    "        imshow(img, cmap='gray')\n",
    "    \n",
    "def get_hsv_param(img, param = 1):\n",
    "    \"\"\"Return h/s/v for each pixel\"\"\"\n",
    "    # param: 0 - hue, 1 - sat, 2 - value\n",
    "    img_sat = []\n",
    "    for row in rgb2hsv(img):\n",
    "        temp = []\n",
    "        for col in row:\n",
    "            temp.append(col[param])\n",
    "        img_sat.append(temp)\n",
    "    img_sat = np.array(img_sat)\n",
    "    return img_sat\n",
    "\n",
    "def oranges(img, low_treshold, high_treshold):\n",
    "    img_oranges = []\n",
    "    for row in rgb2hsv(img):\n",
    "        temp = []\n",
    "        for col in row:\n",
    "            hue = col[0]\n",
    "            if (hue > low_treshold and hue < high_treshold): \n",
    "                temp.append(1)\n",
    "            else: \n",
    "                temp.append(0)\n",
    "        img_oranges.append(temp)\n",
    "    return img_oranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tram_names = [\"1_02\"] #, \"2_01\", \"5_14\", \"4_04\",\"5_07\",\"5_12\",\"6_02\"\n",
    "tram = \"5_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ae4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "for tram in tram_names:\n",
    "    # Read image\n",
    "    img = imread(\"dane/\"+tram+\".jpg\")\n",
    "    img_sat = get_hsv_param(img, 1)\n",
    "\n",
    "    elevation_map = sobel(img_sat)\n",
    "    # show(elevation_map)\n",
    "\n",
    "    markers = np.zeros_like(img_sat)\n",
    "    markers[img_sat < 0.4] = 1\n",
    "    markers[img_sat > 0.95] = 2\n",
    "\n",
    "    segmentation = watershed(elevation_map, markers)\n",
    "    segmentation = ndi.binary_fill_holes(segmentation - 1)\n",
    "\n",
    "    label_objects, nb_labels = ndi.label(segmentation)\n",
    "\n",
    "    sizes = np.bincount(label_objects.ravel())\n",
    "    sizes\n",
    "    mask_sizes = sizes > 80\n",
    "    mask_sizes[0] = 0\n",
    "    cleaned = mask_sizes[label_objects]\n",
    "    print(cleaned)\n",
    "    \n",
    "#     contours, hierarchy = cv2.findContours(np.array(cleaned).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "\n",
    "    show(img, cleaned)\n",
    "\n",
    "    # contour_info = [(c, cv2.contourArea(c),) for c in cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)[1]]\n",
    "    # contour_info\n",
    "    imgs.append(cleaned)\n",
    "show_array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "# for tram in tram_names:\n",
    "img = imread(\"dane/\"+tram+\".jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "edged = cv2.Canny(blurred, 50, 200, 255)\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(img, contour_list, -1, (0,255,0), 3)\n",
    "# cv2.drawContours(img_contoured, contours, -1, (255,0,0),3)\n",
    "show(img)\n",
    "contours\n",
    "#     imgs.append(gray)\n",
    "#     imgs.append(edged)\n",
    "# show_array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66920921",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, hist_centers = exposure.histogram(img_sat)\n",
    "plt.plot(hist_centers, hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc728c",
   "metadata": {},
   "source": [
    "# ideas:\n",
    "1. więcej preprocessingu (jakieś podbijanie kontrastu, rozmycie, ustalenie jasności...)\n",
    "1. operowanie jednak na skali szarości?\n",
    "1. łączenie rozpoznanych obiektów ze skali szarości i z nasycenia\n",
    "1. jakoś inaczej dobrać parametry przed canny?   \n",
    "    - Inne rozmycie? \n",
    "    - cv2.bilateralFilter(rawImage, 5, 175, 175) zamiast gaussian?\n",
    "\n",
    "1. zmniejszenie rozdzielczości? (Czy to ma jakieś znaczenie)\n",
    "1. wykryć koła, sprawdzić ich wielkość, wyciąć i tam szukać lizczb tym algorytmem, który mam\n",
    "    - może być wiele kół, może nie wykryć poprawnie koła\n",
    "\n",
    "\n",
    "Raczej nie:\n",
    "1. wykryć największy obiekt (prawdopodobnie to będzie tramwaj) i szukać na górze od niego\n",
    "    - największy może nie być tramwaj, może wykrywać tramwaj w częściach\n",
    "1. ograniczyć szukanie tylko do górnej połowy zdjęcia, obciąć boki\n",
    "    - jest ryzyko, że tam właśnie będzie numer, bo zdjęcie będzie słabe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a8372",
   "metadata": {},
   "source": [
    "- transformata hougha - raczej nieprzydatna\n",
    "- momenty hu - do rozpoznawania koła?\n",
    "- cv2.find_contorurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4124697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jup_ml)",
   "language": "python",
   "name": "conda_jup_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
